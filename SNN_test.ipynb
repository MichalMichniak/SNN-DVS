{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Spiking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_spiking(tj, W, D_i, t_min, t_max, noise, dtype=torch.FloatTensor):\n",
    "    \"\"\"\n",
    "    Calculates spiking times to recover ReLU-like functionality.\n",
    "    Assumes tau_c=1 and B_i^(n)=1.\n",
    "    \"\"\"\n",
    "    # Calculate the spiking threshold (Eq. 18)\n",
    "    threshold = t_max - t_min - D_i\n",
    "    \n",
    "    # Calculate output spiking time ti (Eq. 7)\n",
    "\n",
    "    ti = torch.matmul((tj - t_min).type(dtype), W.type(dtype)) + threshold + t_min\n",
    "    \n",
    "    # Ensure valid spiking time: do not spike for ti >= t_max\n",
    "    ti = torch.where(ti < t_max, ti, t_max)\n",
    "\n",
    "    # Add noise to the spiking time for noise simulations\n",
    "    if noise > 0:\n",
    "        ti = ti + torch.randn_like(ti) * noise\n",
    "    \n",
    "    return ti\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingDense(nn.Module):\n",
    "    def __init__(self, units, name, X_n=1, outputLayer=False, robustness_params={}, input_dim=None,\n",
    "                 kernel_regularizer=None, kernel_initializer=None):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.B_n = (1 + 0.0) * X_n\n",
    "        self.outputLayer=outputLayer\n",
    "        self.t_min_prev, self.t_min, self.t_max=0, 0, 1\n",
    "        self.noise=robustness_params['noise']\n",
    "        self.time_bits=robustness_params['time_bits']\n",
    "        self.weight_bits =robustness_params['weight_bits'] \n",
    "        self.w_min, self.w_max=-1.0, 1.0\n",
    "        self.alpha = torch.full((units,), 1, dtype=torch.float64)\n",
    "        self.input_dim=input_dim\n",
    "        self.regularizer = kernel_regularizer\n",
    "        self.initializer = kernel_initializer\n",
    "        self.bias = False\n",
    "    \n",
    "    def build(self, input_dim, kernel : torch.Tensor = None, bias : torch.Tensor = None):\n",
    "        # Ensure input_dim is defined properly if not passed.\n",
    "        if input_dim[-1] is None:\n",
    "            input_dim = (None, self.input_dim)\n",
    "        else:\n",
    "            self.input_dim = input_dim\n",
    "        # Create kernel weights and D_i.\n",
    "        if kernel is not None:\n",
    "            if bias is None:\n",
    "                self.kernel = nn.Parameter(kernel.clone())\n",
    "            else:\n",
    "                self.kernel = nn.Parameter(torch.concat((kernel.clone(),bias.clone().unsqueeze(0))))\n",
    "                self.bias = True\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(torch.empty(input_dim[-1], self.units))\n",
    "        self.D_i = nn.Parameter(torch.zeros(self.units))\n",
    "\n",
    "        # Apply the initializer if provided.\n",
    "        if self.initializer:\n",
    "            self.kernel = self.initializer(self.kernel) # tu zmiana TODO\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max parameters of this layer. Alpha is fixed at 1.\n",
    "        \"\"\"\n",
    "        max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape))\n",
    "        if self.bias:\n",
    "            max_input = torch.concat(((t_min - t_min_prev) * torch.ones(self.input_dim), torch.tensor([(1)])))\n",
    "        else:\n",
    "            max_input = (t_min - t_min_prev) * torch.ones(self.input_dim)\n",
    "        max_V = torch.max(torch.matmul(max_input,max_W))\n",
    "\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return t_min, t_min + self.B_n*max_V\n",
    "    \n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times `tj`, output spiking times `ti` or membrane potential value for the output layer.\n",
    "        \"\"\"\n",
    "        # Call the custom spiking logic\n",
    "        if self.bias:\n",
    "            print(tj.shape)\n",
    "            new_tj = torch.concat((tj, torch.tensor([[(self.t_min - 1)]])), dim=1)\n",
    "            output = call_spiking(new_tj, self.kernel, self.D_i, self.t_min, self.t_max, noise=self.noise)\n",
    "        else:\n",
    "            output = call_spiking(tj, self.kernel, self.D_i, self.t_min, self.t_max, noise=self.noise)\n",
    "        # If this is the output layer, perform the special integration logic\n",
    "        if self.outputLayer:\n",
    "            # Compute weighted product\n",
    "            W_mult_x = torch.matmul(self.t_min - tj, self.kernel)\n",
    "            self.alpha = self.D_i / (self.t_min - self.t_min_prev)\n",
    "            output = self.alpha * (self.t_min - self.t_min_prev) + W_mult_x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tensor(5.0893, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\1706425233.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "robustness_params={\n",
    "    'noise':0.0,\n",
    "    'time_bits':0,\n",
    "    'weight_bits': 0,\n",
    "    'latency_quantiles':0.0\n",
    "}\n",
    "\n",
    "spiking_dense = SpikingDense(4,\"test\",robustness_params=robustness_params)\n",
    "weights = torch.rand(6,4,dtype=torch.float32)\n",
    "spiking_dense.build((6,),weights)\n",
    "t_min, t_max = spiking_dense.set_params(1,2)\n",
    "print(t_min, t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9605e-08)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t_input = torch.tensor([1,0,1,0,1,1],dtype=torch.float32)+1\n",
    "inputs= 2 - t_input\n",
    "linear_troch = torch.nn.Linear(6,4, bias=False)\n",
    "linear_troch.weight = nn.parameter.Parameter(weights.T)\n",
    "gtruth = linear_troch(inputs)\n",
    "print(max(spiking_dense.t_max - spiking_dense(t_input)- gtruth).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiking Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingConv2D(nn.Module):\n",
    "    def __init__(self, filters, name, X_n=1, padding='same', kernel_size=(3,3), robustness_params=None, kernels = None, device = 'cuda:0', biases = None, stride=1):\n",
    "        super(SpikingConv2D, self).__init__()\n",
    "        self.stride = stride\n",
    "        if robustness_params is None:\n",
    "            robustness_params = {}\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.B_n = (1 + 0.0) * X_n\n",
    "        self.t_min_prev, self.t_min, self.t_max = 0, 0, 1\n",
    "        self.w_min, self.w_max = -1.0, 1.0\n",
    "        self.time_bits = robustness_params.get('time_bits', 1)\n",
    "        self.weight_bits = robustness_params.get('weight_bits', 1) \n",
    "        self.noise = robustness_params.get('noise', 0.0)\n",
    "        self.device = device\n",
    "        # Initialize alpha as a tensor of ones\n",
    "        self.alpha = nn.Parameter(torch.ones(filters, dtype=torch.float32))\n",
    "        \n",
    "        # Registering the kernel as a learnable parameter\n",
    "        #TODO:\n",
    "        if kernels is not None:\n",
    "            self.kernel = nn.Parameter(kernels).to(device)\n",
    "        else:\n",
    "            self.kernel = nn.Parameter(torch.randn(filters, 1, kernel_size[0], kernel_size[1], dtype=torch.float32)).to(device)\n",
    "        if biases is not None:\n",
    "            self.B = biases.unsqueeze(1).to(self.device)\n",
    "        else:\n",
    "            self.B = nn.Parameter(torch.zeros(filters, 1, dtype=torch.float32)).to(self.device)\n",
    "\n",
    "        # Placeholder for batch normalization parameters\n",
    "        self.BN = nn.Parameter(torch.tensor([0], dtype=torch.float32), requires_grad=False)\n",
    "        self.BN_before_ReLU = nn.Parameter(torch.tensor([0], dtype=torch.float32), requires_grad=False)\n",
    "        \n",
    "        # Parameter for different thresholds\n",
    "        self.D_i = nn.Parameter(torch.zeros(9, filters, dtype=torch.float32)).to(self.device)\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, minimal_t_max = 0):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        max_W = torch.maximum(self.kernel,torch.zeros(self.kernel.shape).to(self.device))\n",
    "        max_input = (t_min - t_min_prev) * torch.ones(self.kernel.shape).to(self.device)\n",
    "        if self.B is not None:\n",
    "            max_V = torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3)) + self.B.unsqueeze(dim=1))\n",
    "        else:\n",
    "            max_V = torch.max(torch.sum(torch.mul(max_input,max_W),(1,2,3)))\n",
    "        self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "\n",
    "        \n",
    "        # Returning for function signature consistency\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max)\n",
    "\n",
    "    def call_spiking(self, tj, W, D_i, t_min, t_max, noise):\n",
    "        \"\"\"\n",
    "        Calculates spiking times from which ReLU functionality can be recovered.\n",
    "        \"\"\"\n",
    "        threshold = t_max - t_min - D_i\n",
    "        \n",
    "        # Calculate output spiking time ti\n",
    "        ti = torch.matmul(tj - t_min, W) + threshold + t_min\n",
    "        \n",
    "        # Ensure valid spiking time\n",
    "        ti = torch.where(ti < t_max, ti, t_max)\n",
    "        \n",
    "        # Add noise\n",
    "        if noise > 0:\n",
    "            ti += torch.randn_like(ti) * noise\n",
    "        \n",
    "        return ti\n",
    "\n",
    "    def forward(self, tj):\n",
    "        \"\"\"\n",
    "        Input spiking times tj, output spiking times ti. \n",
    "        \"\"\"\n",
    "        if self.stride==1:\n",
    "            padding_size = int(self.padding == 'same') * ((self.kernel_size[0]-1) // 2)\n",
    "        else:\n",
    "            # dont know if it works with stride other than 1 always set padding to valid\n",
    "            padding_size = int(self.padding == 'same') * ((self.kernel_size[0]-1) // 2)\n",
    "        image_same_size = tj.size(2) \n",
    "        image_valid_size = image_same_size - self.kernel_size[0] + 1\n",
    "        \n",
    "        # # Pad input with t_min value, equivalent to 0 in ReLU network\n",
    "        # tj = torch.nn.functional.pad(tj.permute((1,2,0)), (0, 0, padding_size, padding_size, padding_size, padding_size), value=self.t_min).permute((2,0,1))\n",
    "        \n",
    "        # # Extract image patches\n",
    "        # tj = torch.nn.functional.unfold(tj.unsqueeze(0), kernel_size=self.kernel_size, stride=1).permute(0, 2, 1).contiguous()\n",
    "        \n",
    "        # # Reshape kernel for fully connected behavior\n",
    "        # W = self.kernel.view(-1, self.filters)\n",
    "\n",
    "        tj_shape = tj.shape\n",
    "        # Dodanie paddingu\n",
    "        if self.padding == 'same':\n",
    "            tj = torch.nn.functional.pad(tj, (padding_size, padding_size, padding_size, padding_size), value=self.t_min)\n",
    "        elif type(self.padding) is tuple:\n",
    "            tj = torch.nn.functional.pad(tj, (self.padding[0], self.padding[0], self.padding[1], self.padding[1]), value=self.t_min)\n",
    "            pass\n",
    "        # Wyciąganie patchy\n",
    "        if self.stride==1:\n",
    "            batch_size, in_channels, input_height, input_width = tj.shape\n",
    "            tj = torch.nn.functional.unfold(tj, kernel_size=self.kernel_size, stride=1).transpose(1, 2)\n",
    "            # Reshape dla wag\n",
    "            W = self.kernel.view(self.filters, -1).t()\n",
    "            out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "            output_height = (input_height - kernel_height) // self.stride + 1\n",
    "            output_width = (input_width - kernel_width) // self.stride + 1\n",
    "        else:\n",
    "            batch_size, in_channels, input_height, input_width = tj.shape\n",
    "            tj = torch.nn.functional.unfold(tj, kernel_size=self.kernel_size, stride=self.stride).transpose(1, 2)\n",
    "            out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "            output_height = (input_height - kernel_height) // self.stride + 1\n",
    "            output_width = (input_width - kernel_width) // self.stride + 1\n",
    "            # Reshape dla wag\n",
    "            W = self.kernel.view(out_channels, -1).t()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (self.padding == 'valid' or self.BN != 1 or self.BN_before_ReLU == 1) and (self.B is None): \n",
    "            # tj = tj.view(-1, W.size(0))\n",
    "            ti = self.call_spiking(tj, W, self.D_i[0], self.t_min, self.t_max, noise=self.noise).transpose(1, 2)\n",
    "            if self.padding == 'valid':\n",
    "                # ti = ti.view(-1, image_valid_size, image_valid_size, self.filters)\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "                #ti = torch.nn.functional.fold(ti, (tj_shape[-1],tj_shape[-1]), (1, 1)) #assuming square input\n",
    "            else:\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "                #ti = torch.nn.functional.fold(ti, (tj_shape[-1],tj_shape[-1]), (1, 1)) #assuming square input\n",
    "                # ti = ti.view(-1, image_same_size, image_same_size, self.filters)\n",
    "        elif self.B is not None:\n",
    "            ## concatenating simple \"one\" to vector of times\n",
    "            one_as_time = self.t_min - 1\n",
    "            tj = torch.concat((tj, one_as_time * torch.ones(tj.shape[0],tj.shape[1],1).to(self.device)), 2)\n",
    "            ## conttenating biases to weight vector\n",
    "            W = torch.concat((W,self.B.T),0)\n",
    "            ti = self.call_spiking(tj, W, self.D_i[0], self.t_min, self.t_max, noise=self.noise).transpose(1, 2)\n",
    "            if self.padding == 'valid':\n",
    "                # ti = ti.view(-1, image_valid_size, image_valid_size, self.filters)\n",
    "                # ti = torch.nn.functional.fold(ti, (tj_shape[-1],tj_shape[-1]), (1, 1)) #assuming square input\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "            else:\n",
    "                # ti = torch.nn.functional.fold(ti, (tj_shape[-1],tj_shape[-1]), (1, 1)) #assuming square input\n",
    "                ti = ti.view(batch_size, out_channels, output_height, output_width)\n",
    "                # ti = ti.view(-1, image_same_size, image_same_size, self.filters)\n",
    "\n",
    "        # else:\n",
    "        #     # Partition the input for different thresholds\n",
    "        #     tj_partitioned = [\n",
    "        #         tj[:, 1:-1, 1:-1], \n",
    "        #         tj[:, :1, :1], \n",
    "        #         tj[:, :1, 1:-1], \n",
    "        #         tj[:, :1, -1:], \n",
    "        #         tj[:, 1:-1, -1:], \n",
    "        #         tj[:, -1:, -1:], \n",
    "        #         tj[:, -1:, 1:-1], \n",
    "        #         tj[:, -1:, :1], \n",
    "        #         tj[:, 1:-1, :1]\n",
    "        #     ]\n",
    "        #     ti_partitioned = []\n",
    "\n",
    "        #     for i, tj_part in enumerate(tj_partitioned):\n",
    "        #         tj_part = tj_part.view(-1, W.size(0))\n",
    "        #         ti_part = self.call_spiking(tj_part, W, self.D_i[i], self.t_min, self.t_max, noise=self.noise)\n",
    "                \n",
    "        #         # Reshape partitions\n",
    "        #         if i == 0: \n",
    "        #             ti_part = ti_part.view(-1, image_valid_size, image_valid_size, self.filters)\n",
    "        #         if i in [1, 3, 5, 7]: \n",
    "        #             ti_part = ti_part.view(-1, 1, 1, self.filters)\n",
    "        #         if i in [2, 6]: \n",
    "        #             ti_part = ti_part.view(-1, 1, image_valid_size, self.filters)\n",
    "        #         if i in [4, 8]: \n",
    "        #             ti_part = ti_part.view(-1, image_valid_size, 1, self.filters)\n",
    "        #         ti_partitioned.append(ti_part) \n",
    "\n",
    "        #     # Concatenate to create a complete output\n",
    "        #     if image_valid_size != 0:\n",
    "        #         ti_top_row = torch.cat([ti_partitioned[1], ti_partitioned[2], ti_partitioned[3]], dim=2)\n",
    "        #         ti_middle = torch.cat([ti_partitioned[8], ti_partitioned[0], ti_partitioned[4]], dim=2)\n",
    "        #         ti_bottom_row = torch.cat([ti_partitioned[7], ti_partitioned[6], ti_partitioned[5]], dim=2)\n",
    "        #         ti = torch.cat([ti_top_row, ti_middle, ti_bottom_row], dim=1)         \n",
    "        #     else:\n",
    "        #         ti_top_row = torch.cat([ti_partitioned[1], ti_partitioned[3]], dim=2)\n",
    "        #         ti_bottom_row = torch.cat([ti_partitioned[7], ti_partitioned[5]], dim=2)\n",
    "        #         ti = torch.cat([ti_top_row, ti_bottom_row], dim=1)\n",
    "\n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "robustness_params={\n",
    "    'noise':0.0,\n",
    "    'time_bits':0,\n",
    "    'weight_bits': 0,\n",
    "    'latency_quantiles':0.0\n",
    "}\n",
    "\n",
    "spiking_conv2 = SpikingConv2D(4,\"test\",robustness_params=robustness_params, device='cpu')\n",
    "weights = torch.ones((6,4),dtype=torch.float32)\n",
    "t_min, t_max = spiking_conv2.set_params(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 7, 7])\n",
      "tensor([[[[0.0000, 1.5698, 1.4425, 2.8032, 1.4425, 1.2334, 0.0000],\n",
      "          [0.0000, 0.7673, 2.0175, 2.8659, 2.0175, 2.0986, 0.0000],\n",
      "          [0.0000, 0.7673, 2.0175, 2.8659, 2.0175, 2.0986, 0.0000],\n",
      "          [0.0000, 0.7673, 2.0175, 2.8659, 2.0175, 2.0986, 0.0000],\n",
      "          [0.0000, 0.7673, 2.0175, 2.8659, 2.0175, 2.0986, 0.0000],\n",
      "          [0.0000, 0.7673, 2.0175, 2.8659, 2.0175, 2.0986, 0.0000],\n",
      "          [0.0000, 0.2570, 1.5047, 2.9200, 1.5047, 2.6630, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 2.2379, 0.0000, 2.2379, 0.0465, 0.0000],\n",
      "          [0.0000, 0.0000, 1.7205, 0.0000, 1.7205, 1.1788, 0.0000],\n",
      "          [0.0000, 0.0000, 1.7205, 0.0000, 1.7205, 1.1788, 0.0000],\n",
      "          [0.0000, 0.0000, 1.7205, 0.0000, 1.7205, 1.1788, 0.0000],\n",
      "          [0.0000, 0.0000, 1.7205, 0.0000, 1.7205, 1.1788, 0.0000],\n",
      "          [0.0000, 0.0000, 1.7205, 0.0000, 1.7205, 1.1788, 0.0000],\n",
      "          [0.0000, 0.0000, 0.8477, 0.0000, 0.8477, 0.9717, 0.0000]],\n",
      "\n",
      "         [[0.0000, 1.7474, 0.0000, 0.8269, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 1.9272, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 1.9272, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 1.9272, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 1.9272, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 1.9272, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 1.6593, 1.2395, 0.0000, 1.2395, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.9473, 0.0000, 0.9473, 0.0000, 0.0000],\n",
      "          [0.0000, 0.1302, 0.3448, 0.8712, 0.3448, 0.7410, 0.0000],\n",
      "          [0.0000, 0.1302, 0.3448, 0.8712, 0.3448, 0.7410, 0.0000],\n",
      "          [0.0000, 0.1302, 0.3448, 0.8712, 0.3448, 0.7410, 0.0000],\n",
      "          [0.0000, 0.1302, 0.3448, 0.8712, 0.3448, 0.7410, 0.0000],\n",
      "          [0.0000, 0.1302, 0.3448, 0.8712, 0.3448, 0.7410, 0.0000],\n",
      "          [0.0000, 0.0000, 1.0420, 0.0000, 1.0420, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "torch.Size([1, 4, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "t_input = torch.tensor([[[1,1,0,1,0,1,1],\n",
    "                        [1,1,0,1,0,1,1],\n",
    "                        [1,1,0,1,0,1,1],\n",
    "                        [1,1,0,1,0,1,1],\n",
    "                        [1,1,0,1,0,1,1],\n",
    "                        [1,1,0,1,0,1,1],\n",
    "                        [1,1,0,1,0,1,1]]],dtype=torch.float32).unsqueeze(0)\n",
    "print(t_input.shape)\n",
    "print(spiking_conv2.t_max - spiking_conv2(t_input))\n",
    "print(spiking_conv2(t_input).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes = 2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.model.conv1 = nn.Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.model.fc = nn.Linear(in_features=2048, out_features=num_classes, bias=True)\n",
    "        self.model.to(\"cuda\")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikos\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"best_resnet50_MINST-DVS.pt\", weights_only=False)\n",
    "model = ResNet(10).to('cuda:0')\n",
    "model.model.load_state_dict(torch.load(\"best_resnet50_MINST-DVS.pt\", weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 64, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(model.model.layer1[0].conv3.weight.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "spiking_conv2 = SpikingConv2D(256,\"test2\",robustness_params=robustness_params,kernels=model.model.layer1[0].conv3.weight.data,kernel_size=(1,1))\n",
    "t_min, t_max = spiking_conv2.set_params(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "t_input = torch.tensor(64*[[[1,1,0,1,0,1,1],\n",
    "                        [1,1,0,1,0,1,1],\n",
    "                        [1,1,0,1,0,1,1],\n",
    "                        [1,1,0,1,0,1,1],\n",
    "                        [1,1,0,1,0,1,1],\n",
    "                        [1,1,0,1,0,1,1],\n",
    "                        [1,1,0,1,0,1,1]]],dtype=torch.float32)\n",
    "print(t_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = model.model.layer1[0].conv3\n",
    "t_input_x = 1-t_input\n",
    "x_torch = nn.ReLU()(conv2d(t_input_x.to(\"cuda\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 7, 7])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 7, 7])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = spiking_conv2(t_input.unsqueeze(0).to(\"cuda\"))\n",
    "x_ttfs = spiking_conv2.t_max-out\n",
    "x_ttfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "out = spiking_conv2(t_input.unsqueeze(0).to(\"cuda\"))\n",
    "x_ttfs = (spiking_conv2.t_max-out)\n",
    "print(x_ttfs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.9407e-08, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# print(x_ttfs.squeeze(0)[0])\n",
    "# print(x_torch.permute(1, 2, 0)[0])\n",
    "print((x_ttfs.squeeze(0)-x_torch).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "torch.Size([256, 64, 1, 1])\n",
      "tensor(1.3970e-09)\n",
      "torch.Size([1, 256, 7, 7])\n",
      "torch.Size([1, 256, 7, 7])\n",
      "tensor(5.9605e-08, grad_fn=<MaxBackward1>)\n",
      "tensor(0.9145, grad_fn=<MaxBackward1>)\n",
      "tensor(5.9605e-08, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inp = 1-t_input\n",
    "inp = inp.unsqueeze(0)\n",
    "print(model.model.layer1[0].conv3)\n",
    "kernel_size = (1,1)\n",
    "padding_size = ((kernel_size[0] - 1) // 2)\n",
    "\n",
    "inp = torch.nn.functional.pad(inp, (padding_size, padding_size, padding_size, padding_size), mode='constant', value=0)\n",
    "w = model.model.layer1[0].conv3.weight.data.to(\"cpu\")\n",
    "print(w.shape)\n",
    "inp_unf = torch.nn.functional.unfold(inp, kernel_size)\n",
    "out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "out = torch.nn.functional.fold(out_unf, (7,7), (1, 1))\n",
    "print((torch.nn.functional.conv2d(inp, w) - out).abs().max())\n",
    "inp = 1-t_input\n",
    "inp = inp.unsqueeze(0)\n",
    "out2 = model.model.layer1[0].conv3(inp.to(\"cuda:0\"))\n",
    "print(out.shape)\n",
    "print(torch.nn.functional.conv2d(inp, w, stride=(1, 1), padding=(0,0)).shape)\n",
    "print((out2.to(\"cpu\") - torch.nn.functional.conv2d(inp, w, stride=(1, 1), padding=(0,0))).abs().max())\n",
    "print((out2.to(\"cpu\")).abs().max())\n",
    "print((model.model.layer1[0].conv3(inp.to(\"cuda:0\"))-torch.nn.functional.conv2d(inp, w, stride=(1, 1), padding=model.model.layer1[0].conv3.padding).to(\"cuda:0\")).abs().max())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 7, 7]) torch.Size([1, 64, 7, 7])\n",
      "tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Max difference (manual conv vs conv2d): tensor(2.9802e-08, grad_fn=<MaxBackward1>)\n",
      "Max difference (model vs conv2d): tensor(0.0001, grad_fn=<MaxBackward1>)\n",
      "Max absolute value (model output): tensor(0.6116, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Max difference (manual vs model): tensor(0.0001, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "conv_layer = model.model.layer1[0].conv2\n",
    "w = conv_layer.weight\n",
    "bias = conv_layer.bias\n",
    "\n",
    "# Prepare input\n",
    "inp = 1 - t_input\n",
    "inp = inp.unsqueeze(0)\n",
    "\n",
    "# Get the conv layer and parameters (bias is None)\n",
    "conv_layer = model.model.layer1[0].conv2\n",
    "w = conv_layer.weight.data.to(\"cpu\")\n",
    "\n",
    "# Manually apply padding for same padding (3x3 kernel, stride 1)\n",
    "kernel_size = (3, 3)\n",
    "padding_size = (kernel_size[0] - 1) // 2\n",
    "\n",
    "# Apply padding to input manually\n",
    "inp2 = torch.nn.functional.pad(inp, (padding_size, padding_size, padding_size, padding_size), mode='constant', value=0)\n",
    "\n",
    "# Unfold input for manual convolution\n",
    "inp_unf = torch.nn.functional.unfold(inp2, kernel_size)\n",
    "\n",
    "# Perform the matrix multiplication with weights reshaped to unfold shape\n",
    "out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "\n",
    "# Correctly reshape before folding, setting kernel size correctly as single-pixel patches\n",
    "out_unf = out_unf.view(1, 64, 49)  # 64 output channels, 49 patches\n",
    "\n",
    "# Calculate the correct output shape (7x7)\n",
    "output_height, output_width = 7, 7\n",
    "\n",
    "# Perform fold\n",
    "out = torch.nn.functional.fold(out_unf, (output_height, output_width), kernel_size=(1, 1))\n",
    "\n",
    "# Compare with torch.nn.functional.conv2d TODO: Tu zmieniać na CPU i GPU\n",
    "out_conv2d = torch.nn.functional.conv2d(inp, conv_layer.weight.to('cpu'), padding=(1, 1)).to(\"cpu\")\n",
    "conv_layer = model.model.layer1[0].conv2\n",
    "w = conv_layer.weight\n",
    "bias = conv_layer.bias\n",
    "# out_conv2d = torch.nn.functional.conv2d(inp.to(\"cuda:0\"), w, padding=(1,1))\n",
    "print(out.shape, out_conv2d.shape)\n",
    "\n",
    "\n",
    "# Use the model's conv2 layer for comparison\n",
    "conv_layer = model.model.layer1[0].conv2\n",
    "out2 = conv_layer(inp.to(\"cuda:0\"))\n",
    "\n",
    "\n",
    "conv_layer = model.model.layer1[0].conv2\n",
    "w = conv_layer.weight\n",
    "bias = conv_layer.bias\n",
    "\n",
    "out1 = conv_layer(inp.to(\"cuda:0\"))\n",
    "# out_conv2d = torch.nn.functional.conv2d(inp.to(\"cuda:0\"), w, padding=(1,1))\n",
    "print((out1 - out2.to(\"cuda:0\")).abs().max())\n",
    "print(\"Max difference (manual conv vs conv2d):\", (out_conv2d.to(\"cpu\") - out.to(\"cpu\")).abs().max())\n",
    "print(\"Max difference (model vs conv2d):\", (out1.to(\"cpu\") - out_conv2d.to(\"cpu\")).abs().max())\n",
    "print(\"Max absolute value (model output):\", out2.abs().max())\n",
    "\n",
    "# Compare manual and model convolutions directly\n",
    "print(\"Max difference (manual vs model):\", (out2.to(\"cpu\") - out).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "conv_layer = model.model.layer1[0].conv2\n",
    "w = conv_layer.weight\n",
    "bias = conv_layer.bias\n",
    "\n",
    "out1 = conv_layer(inp.to(\"cuda:0\"))\n",
    "out2 = torch.nn.functional.conv2d(inp.to(\"cuda:0\"), w, padding=(1,1))\n",
    "print((out1 - out2.to(\"cuda:0\")).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7220e-06)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn(1, 3, 10, 12)\n",
    "w = torch.randn(2, 3, 4, 5)\n",
    "inp_unf = torch.nn.functional.unfold(inp, (4, 5))\n",
    "out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1))\n",
    "# or equivalently (and avoiding a copy),\n",
    "out = out_unf.view(1, 2, 7, 8)\n",
    "(torch.nn.functional.conv2d(inp, w) - out).abs().max()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuse batch normalization + conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_and_bn(conv, bn, device = 'cuda:0'):\n",
    "\t#\n",
    "\t# init\n",
    "\tfusedconv = torch.nn.Conv2d(\n",
    "\t\tconv.in_channels,\n",
    "\t\tconv.out_channels,\n",
    "\t\tkernel_size=conv.kernel_size,\n",
    "\t\tstride=conv.stride,\n",
    "\t\tpadding=conv.padding,\n",
    "\t\tbias=True\n",
    "\t)\n",
    "\t#\n",
    "\t# prepare filters\n",
    "\tw_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "\tw_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps+bn.running_var)))\n",
    "\twith torch.no_grad():\n",
    "\t\tfusedconv.weight.copy_( torch.mm(w_bn, w_conv).view(fusedconv.weight.size()) )\n",
    "\t#\n",
    "\t# prepare spatial bias\n",
    "\tif conv.bias is not None:\n",
    "\t\tb_conv = conv.bias\n",
    "\telse:\n",
    "\t\tb_conv = torch.zeros( conv.weight.size(0) ).to(device)\n",
    "\tb_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
    "\twith torch.no_grad():\n",
    "\t\tfusedconv.bias.copy_( (torch.matmul(w_bn, b_conv) + b_bn) )\n",
    "\t\n",
    "\treturn fusedconv.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = model.model.layer1[0].conv3\n",
    "bias_from_nn = model.model.layer1[0].bn3\n",
    "bias_from_nn.eval()\n",
    "net = torch.nn.Sequential(\n",
    "\tmodel.model.layer1[0].conv3,\n",
    "\tmodel.model.layer1[0].bn3,\n",
    "    nn.ReLU()\n",
    ")\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_fused = fuse_conv_and_bn(conv2d, bias_from_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "spiking_conv2 = SpikingConv2D(256,\"test2\",robustness_params=robustness_params,kernels=conv_fused.weight.data, biases=conv_fused.bias, kernel_size=(1,1))\n",
    "t_min, t_max = spiking_conv2.set_params(0,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_fused.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "out = spiking_conv2(t_input.unsqueeze(0).to(\"cuda\"))\n",
    "x_ttfs = (spiking_conv2.t_max-out)\n",
    "print(x_ttfs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.4907, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3.8831, device='cuda:0', grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(out.max())\n",
    "print(out.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_input_x = 1-t_input\n",
    "x_torch = (net(t_input_x.unsqueeze(0).to(\"cuda\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.5367e-07, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((x_ttfs.squeeze(0)-x_torch).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(9.5367e-07, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4.8420, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "conv2d = model.model.layer1[0].conv3\n",
    "bias_from_nn = model.model.layer1[0].bn3\n",
    "bias_from_nn.eval()\n",
    "\n",
    "\n",
    "inp = 1-t_input\n",
    "inp = inp.unsqueeze(0).to(\"cuda:0\")\n",
    "\n",
    "kernel_size = (1,1)\n",
    "padding_size = (kernel_size[0] // 2)\n",
    "\n",
    "inp2 = torch.nn.functional.pad(inp, (padding_size, padding_size, padding_size, padding_size), value=0)\n",
    "w = conv_fused.weight.data\n",
    "inp_unf = torch.nn.functional.unfold(inp2, (1,1))\n",
    "out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "out = torch.nn.functional.fold(out_unf, (7,7), (1, 1))\n",
    "out = out + conv_fused.bias.data.view(1, 256, 1, 1) \n",
    "print((torch.nn.functional.conv2d(inp, w, bias=conv_fused.bias, padding=(padding_size,padding_size)) - out).abs().max())\n",
    "\n",
    "inp = 1-t_input\n",
    "inp = inp.unsqueeze(0)\n",
    "model.model.layer1[0].bn1.eval()\n",
    "net2 = torch.nn.Sequential(\n",
    "\tmodel.model.layer1[0].conv3,\n",
    "\tmodel.model.layer1[0].bn3\n",
    ")\n",
    "out2 = net2(inp.to(\"cuda:0\"))\n",
    "print((out2 - out.to(\"cuda:0\")).abs().max())\n",
    "print((out2.to(\"cpu\")).abs().max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 7, 8])\n",
      "torch.Size([1, 2, 7, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[  5.4809,  -2.7389,  -3.7882,   2.2093,  -7.7872,  -1.2644,   4.9757,\n",
       "             1.7292],\n",
       "          [  1.8345,  -4.8786,   3.3867,   8.9886,   2.9018,  -4.8675,   6.4918,\n",
       "            -2.8426],\n",
       "          [ -5.7101,   4.2118,  -5.6737,   3.9756, -13.9600,   2.1439,   9.3056,\n",
       "            -3.7186],\n",
       "          [ -2.4305,   6.8247,  -2.5439, -11.5840,  -0.2728,   7.4573,   9.6497,\n",
       "             2.9581],\n",
       "          [ -7.5298,   1.8119,   2.3664,   1.0599,   2.2424,  10.6940,   5.9245,\n",
       "            -4.1176],\n",
       "          [  4.2635,   3.0588,  -3.3941,   3.0237,  -0.8737,  -5.9769,  -2.0083,\n",
       "            -0.8135],\n",
       "          [ -4.9533,   1.0196,   5.6690,  -0.6195,  -2.5856,  -1.3279,   1.9264,\n",
       "            -2.3364]],\n",
       "\n",
       "         [[  1.5712,   0.5898,  -5.0947,  -3.3988,  -6.9160,  -4.6906,  -1.6789,\n",
       "            -0.4998],\n",
       "          [  3.5965,  -6.4140,   1.7303,   5.3076,  -1.4501,  -7.1534,   1.6064,\n",
       "            -3.3670],\n",
       "          [  9.7327,  -9.5707, -17.1044,   9.8836,  15.9195,  -0.3299,   2.0523,\n",
       "           -10.5809],\n",
       "          [ -2.0733,  -1.6640,  -3.3048,   0.3595,  -2.7917,  -2.1287,  -5.9909,\n",
       "            -3.5495],\n",
       "          [ -9.6445,  10.7995,  18.0182,   0.3672,  -7.9033,  -1.8515,  14.6106,\n",
       "            -3.4609],\n",
       "          [  2.1673,  -1.3043,   7.6838, -14.9902,   0.0414,  -9.2152,   1.0274,\n",
       "             0.9161],\n",
       "          [  1.8851,   3.2490, -14.1443,   1.9573,   1.9696,  -0.0768,  -0.2317,\n",
       "             2.2599]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn(1, 3, 10, 12)\n",
    "w = torch.randn(2, 3, 4, 5)\n",
    "inp_unf = torch.nn.functional.unfold(inp, (4, 5), stride=(2,2))\n",
    "out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1), stride=(2,2))\n",
    "# or equivalently (and avoiding a copy),\n",
    "# out = out_unf.view(1, 2, 7, 8)\n",
    "print(out.shape)\n",
    "print(torch.nn.functional.conv2d(inp, w,stride= (2,2), padding=(3,4)).shape)\n",
    "(torch.nn.functional.conv2d(inp, w ,stride= (2,2), padding=(3,4)) - out)#.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"best_resnet50_MINST-DVS.pt\", weights_only=False)\n",
    "model = ResNet(10).to('cuda:0')\n",
    "model.model.load_state_dict(torch.load(\"best_resnet50_MINST-DVS.pt\", weights_only=True))\n",
    "model.eval()\n",
    "inp = torch.randn(1, 5, 10, 12)\n",
    "conv = model.model.conv1\n",
    "print(conv(inp.to('cuda')).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 1, 1])\n",
      "torch.Size([1, 64, 1, 1])\n",
      "tensor(1.5259e-05)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv2d_stride(input_tensor, weight, bias=None, stride=2):\n",
    "    # Wymiary wejściowego obrazu\n",
    "    batch_size, in_channels, input_height, input_width = input_tensor.shape\n",
    "    out_channels, _, kernel_height, kernel_width = weight.shape\n",
    "    \n",
    "    # Obliczanie wymiarów obrazu wyjściowego na podstawie stride\n",
    "    output_height = (input_height - kernel_height) // stride + 1\n",
    "    output_width = (input_width - kernel_width) // stride + 1\n",
    "    \n",
    "    # Rozwijanie obrazu do fragmentów (patches)\n",
    "    unfolded_input = F.unfold(input_tensor, kernel_size=(kernel_height, kernel_width), stride=stride)\n",
    "    \n",
    "    # Mnożenie rozwiniętych fragmentów przez wagi\n",
    "    unfolded_output = weight.view(out_channels, -1) @ unfolded_input\n",
    "    if bias is not None:\n",
    "        unfolded_output += bias.view(1, -1, 1)\n",
    "    \n",
    "    # Składanie wyników z powrotem do obrazu wyjściowego\n",
    "    output_tensor = unfolded_output.view(batch_size, out_channels, output_height, output_width)\n",
    "    \n",
    "    return output_tensor\n",
    "\n",
    "# Przykład użycia:\n",
    "batch_size = 1\n",
    "in_channels = 5\n",
    "out_channels = 64\n",
    "input_height = 7\n",
    "input_width = 7\n",
    "kernel_height = 7\n",
    "kernel_width = 7\n",
    "\n",
    "# Tworzymy przykładowe dane wejściowe i wagi\n",
    "input_tensor = torch.randn(batch_size, in_channels, input_height, input_width)\n",
    "weight = torch.randn(out_channels, in_channels, kernel_height, kernel_width)\n",
    "bias = torch.randn(out_channels)\n",
    "\n",
    "# Przeprowadzamy konwolucję\n",
    "output_tensor1 = conv2d_stride(input_tensor, weight, bias)\n",
    "print(output_tensor1.shape)  # Sprawdzamy wynikowy kształt\n",
    "\n",
    "# Wykonanie konwolucji\n",
    "output_tensor2 = F.conv2d(input_tensor, weight, bias, stride=2)\n",
    "print(output_tensor2.shape)  # Sprawdzamy wynikowy kształt\n",
    "print((output_tensor1-output_tensor2).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pierwsza konwolucja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"best_resnet50_MINST-DVS.pt\", weights_only=False)\n",
    "model = ResNet(10).to('cuda:0')\n",
    "model.model.load_state_dict(torch.load(\"best_resnet50_MINST-DVS.pt\", weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "spiking_conv2 = SpikingConv2D(64,\"test2\",padding=(3,3),robustness_params=robustness_params,kernels=model.model.conv1.weight.data,kernel_size=(7,7),stride=2)\n",
    "t_min, t_max = spiking_conv2.set_params(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# t_input = torch.tensor(5*[[[1,1,0,1,0,1,1],\n",
    "#                         [1,1,0,1,0,1,1],\n",
    "#                         [1,1,0,1,0,1,1],\n",
    "#                         [1,1,0,1,0,1,1],\n",
    "#                         [1,1,0,1,0,1,1],\n",
    "#                         [1,1,0,1,0,1,1],\n",
    "#                         [1,1,0,1,0,1,1]]],dtype=torch.float32)\n",
    "t_input = torch.rand(1,5,64,64)\n",
    "print(t_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = model.model.conv1\n",
    "\n",
    "t_input_x = 1-t_input\n",
    "x_torch = nn.ReLU()(conv2d(t_input_x.to(\"cuda\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 32, 32])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = spiking_conv2(t_input.to(\"cuda\"))\n",
    "x_ttfs = spiking_conv2.t_max-out\n",
    "x_ttfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 32, 32])\n",
      "torch.Size([64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(x_torch.shape)\n",
    "print(x_ttfs.squeeze(0).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7881e-06, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((x_ttfs.squeeze(0)-x_torch).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaxMinPool2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Max Pooling or Min Pooling operation, depending on the sign of the batch normalization layer before.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, max_time, stride=None, padding=0, dilation=1):\n",
    "        super(MaxMinPool2D, self).__init__()\n",
    "        \n",
    "        # Default sign is 1, indicating max pooling functionality.\n",
    "        self.sign = nn.Parameter(-1*torch.ones(1, 1, 1, 1), requires_grad=False)\n",
    "        self.dilation = dilation\n",
    "        # MaxPool2d setup (will be used in call)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.max_time = max_time\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Applying the sign to the inputs (if sign is -1, it will act as Min Pooling)\n",
    "        padding_size = self.padding\n",
    "        inputs = torch.nn.functional.pad(inputs, (padding_size, padding_size, padding_size, padding_size), value=self.max_time)\n",
    "        pooled = F.max_pool2d(self.sign * inputs, kernel_size=self.kernel_size, stride=self.stride, padding=0, dilation=self.dilation)\n",
    "        \n",
    "        # Multiply the pooled result by the sign, which controls the pooling type\n",
    "        return pooled * self.sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 10, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 5, 6])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = MaxMinPool2D(2,0)\n",
    "inp2 = torch.nn.functional.pad(inp, (padding_size, padding_size, padding_size, padding_size), mode='constant', value=0)\n",
    "print(inp2.shape)\n",
    "pool(inp2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaptiveAvgPool (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 22, 22])\n",
      "torch.Size([1, 1, 22, 22])\n",
      "tensor(1.1176e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AvgPool2dToConv2d(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(AvgPool2dToConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=kernel_size, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        # Initialize weights to simulate average pooling behavior\n",
    "        with torch.no_grad():\n",
    "            self.conv.weight.fill_(1.0 / (kernel_size * kernel_size))  # Fill the kernel with 1/49 to average over a 7x7 window\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Example usage:\n",
    "model = AvgPool2dToConv2d().conv\n",
    "avg_pool = nn.AvgPool2d(7, stride=1)\n",
    "input_tensor = torch.randn(1, 1, 28, 28)  # Example input tensor of shape (batch_size, channels, height, width)\n",
    "output = model(input_tensor)\n",
    "output_avg_pool = avg_pool(input_tensor)\n",
    "print(output.shape)\n",
    "print(output_avg_pool.shape)\n",
    "print(torch.abs(output - output_avg_pool).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"best_resnet50_MINST-DVS.pt\", weights_only=False)\n",
    "model = ResNet(10).to('cuda:0')\n",
    "model.model.load_state_dict(torch.load(\"best_resnet50_MINST-DVS.pt\", weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddSNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, minimal_t_max = 0):\n",
    "        max_input = (t_min - t_min_prev)\n",
    "        max_V = max_input * 2\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max)\n",
    "\n",
    "    def forward(self, tj1, tj2):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ti = tj1 + tj2 - 2*self.t_min  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4., dtype=torch.float64) tensor(8., dtype=torch.float64)\n",
      "tensor(4.7684e-07)\n"
     ]
    }
   ],
   "source": [
    "batch = 8\n",
    "channel = 3\n",
    "width = 64\n",
    "height = 64\n",
    "random_tensor1 = torch.rand(batch, channel, width, height)\n",
    "random_tensor2 = torch.rand(batch, channel, width, height)\n",
    "\n",
    "# random_tensor1 = torch.ones(batch, channel, width, height)\n",
    "# random_tensor2 = torch.ones(batch, channel, width, height)\n",
    "\n",
    "# random_tensor1 = torch.zeros(batch, channel, width, height)\n",
    "# random_tensor2 = torch.zeros(batch, channel, width, height)\n",
    "\n",
    "t_min_prev = 2\n",
    "t_max_prev = 4\n",
    "\n",
    "input1 = t_max_prev - random_tensor1\n",
    "input2 = t_max_prev - random_tensor2\n",
    "\n",
    "addlayer = AddSNNLayer()\n",
    "addlayer.set_params(t_min_prev, t_max_prev, 0)\n",
    "result = addlayer(input1, input2)\n",
    "gtruth = random_tensor1 + random_tensor2\n",
    "print(addlayer.t_min,addlayer.t_max)\n",
    "print((addlayer.t_max-result - gtruth).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentitySNNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentitySNNLayer, self).__init__()\n",
    "        self.noise = 0\n",
    "        self.B_n = 1\n",
    "        pass\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, minimal_t_max = 0):\n",
    "        max_input = (t_min - t_min_prev)\n",
    "        max_V = max_input\n",
    "        self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
    "        self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
    "        return t_min, max(t_min + self.B_n*max_V, minimal_t_max)\n",
    "\n",
    "    def forward(self, tj):\n",
    "        D_i = 0\n",
    "        threshold = self.t_max - self.t_min - D_i\n",
    "        \n",
    "        ti = tj - self.t_min  + threshold + self.t_min\n",
    "\n",
    "        ti = torch.where(ti < self.t_max, ti, self.t_max)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            ti += torch.randn_like(ti) * self.noise\n",
    "        \n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5565e-07)\n"
     ]
    }
   ],
   "source": [
    "batch = 8\n",
    "channel = 3\n",
    "width = 64\n",
    "height = 64\n",
    "random_tensor = torch.rand(batch, channel, width, height)\n",
    "\n",
    "t_min_prev = 4\n",
    "t_max_prev = 8\n",
    "\n",
    "input1 = t_max_prev - random_tensor\n",
    "\n",
    "idlayer = IdentitySNNLayer()\n",
    "idlayer.set_params(t_min_prev, t_max_prev,2)\n",
    "result = idlayer(input1)\n",
    "gtruth = random_tensor\n",
    "print((idlayer.t_max-result - gtruth).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU(inplace=False))  # Changed inplace to False\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU(inplace=False))  # Changed inplace to False\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU(inplace=False)  # Changed inplace to False\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out = out + residual\n",
    "        out = F.relu(out, inplace=False)   # Use non-in-place ReLU\n",
    "        return out\n",
    "\n",
    "class ResNet2(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 2):\n",
    "        super(ResNet2, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(5, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU(inplace=False))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes),\n",
    "                nn.ReLU(inplace=False)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def train_model(self, train_loader, valid_loader, num_epochs = 5, learning_rate=0.001, save_best = False, save_thr = 0.94):\n",
    "        best_accuracy = 0.0\n",
    "        total_step = len(train_loader)\n",
    "        # Loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.RMSprop(self.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # self.train()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "                # Move tensors to the configured device\n",
    "                images = images.float().to(\"cuda\")\n",
    "                labels = labels.type(torch.LongTensor)\n",
    "                labels = labels.to(\"cuda\")\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.forward(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                # Backward and optimize\n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "\n",
    "                # accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (torch.eq(predicted, labels)).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                del images, labels, outputs\n",
    "\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}'\n",
    "                            .format(epoch+1, num_epochs, i+1, total_step, loss.item(), (float(correct))/total))\n",
    "\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # Validation\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for images, labels in valid_loader:\n",
    "                    images = images.float().to(\"cuda\")\n",
    "                    labels = labels.to(\"cuda\")\n",
    "                    outputs = self.forward(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (torch.eq(predicted, labels)).sum().item()\n",
    "                    del images, labels, outputs\n",
    "                if(((100 * correct / total) > best_accuracy) and save_best and ((100 * correct / total) > save_thr)):\n",
    "                    torch.save(self.state_dict(), \"best_resnet50_MINST-DVS2.pt\")\n",
    "\n",
    "                print('Accuracy of the network: {} %'.format( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ResNet2(ResidualBlock, [3, 4, 6, 3], num_classes = 10).to(\"cuda\")\n",
    "model2.load_state_dict(torch.load(\"best_resnet50_MINST-DVS2.pt\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet2(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer0): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResidualBlockSNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualSNNBlock(nn.Module):\n",
    "    def __init__(self,resblock : ResidualBlock, in_channels, out_channels, stride=1, downsample=None, robustness_params = None, device = \"cuda:0\"):\n",
    "        super(ResidualSNNBlock, self).__init__()\n",
    "        conv = resblock.conv1[0]\n",
    "        bn= resblock.conv1[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv1 = SpikingConv2D(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "        self.device = device\n",
    "        \n",
    "        conv = resblock.conv2[0]\n",
    "        bn= resblock.conv2[1]\n",
    "        bn.eval()\n",
    "        conv_fused = fuse_conv_and_bn(conv, bn)\n",
    "        self.conv2 = SpikingConv2D(out_channels, \"temp1\", device=device, padding=(1,1), stride=stride, kernel_size=(3,3),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.identity = IdentitySNNLayer()\n",
    "        self.add_layer = AddSNNLayer()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def set_params(self, t_min_prev, t_min, minimal_t_max = 0):\n",
    "        \"\"\"\n",
    "        Set t_min_prev, t_min, t_max, J_ij (kernel) and vartheta_i (threshold) parameters of this layer.\n",
    "        \"\"\"\n",
    "        t_min1, t_max1 = self.conv1.set_params(t_min_prev=t_min_prev,t_min=t_min)\n",
    "        self.pooling1 = MaxMinPool2D(2, t_max1.data,2).to(self.device)\n",
    "        t_min2, t_max2 = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1)\n",
    "        max_out2 = t_max2 - t_min2\n",
    "        \n",
    "        if self.downsample:\n",
    "            t_min_dummy, t_max1_dummy = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy = self.downsample.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2)\n",
    "            self.pooling2 = MaxMinPool2D(2, t_max1_dummy.data,2).to(self.device)\n",
    "        else:\n",
    "            t_min_dummy, t_max1_dummy = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min)\n",
    "            max_dummy1 = t_max1_dummy - t_min_dummy\n",
    "            t_min_dummy, t_max1_dummy = self.identity.set_params(t_min_prev=t_min_prev,t_min=t_min,minimal_t_max=t_max2)\n",
    "\n",
    "        t_min2, t_max2 = self.conv2.set_params(t_min_prev=t_min1,t_min=t_max1, minimal_t_max=t_max1_dummy)\n",
    "        \n",
    "        # time t_max2 and t_max1_dummy are the same\n",
    "        t_min_add = t_max2 - max(max_dummy1, max_out2)\n",
    "\n",
    "        self.t_min, self.t_max = self.add_layer.set_params(t_min_add, t_max2)\n",
    "        self.times = [(t_min1, t_max1, 'c'), (t_min2, t_max2, 'c'), (self.t_min, self.t_max, 'a') ]\n",
    "        return self.t_min, self.t_max\n",
    "    \n",
    "\n",
    "    def get_main_times(self):\n",
    "        return self.times\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            residual = self.pooling2(residual)\n",
    "            out = self.pooling1(out)\n",
    "        else:\n",
    "            residual = self.identity(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.add_layer(out,residual)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Block Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.9574, device='cuda:0', grad_fn=<AddBackward0>) tensor(19.4075, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\3544665386.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\1180262121.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dummy = None\n",
    "\n",
    "resblockSNN = ResidualSNNBlock(model2.layer0[0],64,64, downsample=dummy)\n",
    "tmin, tmax = resblockSNN.set_params(0,1)\n",
    "print(tmin,tmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0004, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "t_max tensor(19.4075, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "random_input = torch.rand(1, 64, 100, 100)\n",
    "out = resblockSNN.t_max - resblockSNN((1-random_input).to(\"cuda\"))\n",
    "model2.layer0[0].eval()\n",
    "out_res = model2.layer0[0](random_input.to(\"cuda\"))\n",
    "print((out - out_res).abs().max())\n",
    "\n",
    "print(\"t_max\", resblockSNN.t_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet2(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer0): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.conv1.eval()\n",
    "model2.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = torch.rand(1, 5, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv1 = model2.conv1(random_input)\n",
    "model_maxpool = model2.maxpool(model_conv1)\n",
    "model_layer0 = model2.layer0(model_maxpool)\n",
    "model_layer1 = model2.layer1(model_layer0)\n",
    "model_layer2 = model2.layer2(model_layer1)\n",
    "model_layer3 = model2.layer3(model_layer2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_fused = fuse_conv_and_bn(model2.conv1[0], model2.conv1[1])\n",
    "conv_first = SpikingConv2D(out_channels, \"temp1\", device = 'cpu', padding=(3,3), stride=2, kernel_size=(7,7),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "tmin, tmax = conv_first.set_params(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.1526e-07, grad_fn=<MaxBackward1>)\n",
      "torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SNN_input = 1 - random_input\n",
    "model2.conv1.eval() ## Important eval for batch normalization\n",
    "out1 = conv_first(SNN_input.to(\"cpu\"))\n",
    "out1_x = model2.conv1(random_input)\n",
    "print(((conv_first.t_max - out1) - out1_x).abs().max())\n",
    "print(out1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5565e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool = MaxMinPool2D(3, tmax.data,2,1).to(\"cpu\")\n",
    "\n",
    "out2 = pool(out1)\n",
    "out2_x = model2.maxpool(out1_x)\n",
    "\n",
    "print(((tmax - out2) - model_maxpool).abs().max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerSNN(nn.Module):\n",
    "    def __init__(self, layer, inplanes, planes, blocks, stride=1, device = 'cuda:0'):\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            conv2d, bias_from_nn = layer[0].downsample[0], layer[0].downsample[1]\n",
    "            conv_fused = fuse_conv_and_bn(conv2d, bias_from_nn)\n",
    "            downsample = SpikingConv2D(planes,\"test2\", padding='same', stride=1, device=device,robustness_params=robustness_params,kernels=conv_fused.weight.data, biases=conv_fused.bias, kernel_size=(1,1))\n",
    "            # t_min, t_max = spiking_conv2.set_params(0,1)stride\n",
    "            \n",
    "        self.layers = []\n",
    "        self.layers.append(ResidualSNNBlock(layer[0],self.inplanes,planes, 1, downsample=downsample, device=device))\n",
    "        self.inplanes = planes\n",
    "        self.blocks = blocks\n",
    "        for i in range(1, blocks):\n",
    "            self.layers.append(ResidualSNNBlock(layer[i],self.inplanes,planes, 1, downsample=None, device=device))\n",
    "        \n",
    "    \n",
    "    def set_params(self, t_min_prev, t_min, minimal_t_max = 0):\n",
    "        tmin, tmax = t_min_prev, t_min\n",
    "        for i in range(self.blocks):\n",
    "            tmin, tmax = self.layers[i].set_params(tmin, tmax)\n",
    "        return tmin, tmax\n",
    "    \n",
    "    def get_main_times(self):\n",
    "        lst = []\n",
    "        for i in range(self.blocks):\n",
    "            lst.extend(self.layers[i].get_main_times())\n",
    "        return lst\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.blocks):\n",
    "            x = self.layers[i].forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\3544665386.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\3544665386.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "layer0SNN = LayerSNN(model2.layer0, 64, 64, 3,device = 'cpu')\n",
    "tmin, tmax = layer0SNN.set_params(tmin, tmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(164.6521, grad_fn=<AddBackward0>) tensor(259.7542, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_3 = layer0SNN.forward(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0006, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax - out_3 - model_layer0).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 wersja sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        if(downsample is not None):\n",
    "            self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.ReLU(inplace=False),\n",
    "                            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                            )  # Changed inplace to False\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
    "                            nn.BatchNorm2d(out_channels),\n",
    "                            nn.ReLU(inplace=False)\n",
    "                            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU(inplace=False))  # Changed inplace to False\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU(inplace=False)  # Changed inplace to False\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out = out + residual\n",
    "        out = F.relu(out, inplace=False)   # Use non-in-place ReLU\n",
    "        return out\n",
    "\n",
    "class ResNet3(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 2):\n",
    "        super(ResNet3, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(5, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU(inplace=False))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "        self.avgpool = nn.MaxPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=1, padding='same'),\n",
    "                nn.BatchNorm2d(planes),\n",
    "                nn.ReLU(inplace=False),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet3(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer0): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): MaxPool2d(kernel_size=7, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ResNet3(ResidualBlock, [3, 4, 6, 3], num_classes = 10).to(\"cpu\")\n",
    "model2.load_state_dict(torch.load(\"best_resnet50_MINST-DVS_with_maxpool_same.pt\", weights_only=True))\n",
    "model2.to(\"cpu\")\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = torch.rand(1, 5, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv1 = model2.conv1(random_input)\n",
    "model_maxpool = model2.maxpool(model_conv1)\n",
    "model_layer0 = model2.layer0(model_maxpool)\n",
    "model_layer1 = model2.layer1(model_layer0)\n",
    "model_layer2 = model2.layer2(model_layer1)\n",
    "model_layer3 = model2.layer3(model_layer2)\n",
    "model_maxpool2 = model2.avgpool(model_layer3)\n",
    "# model2.fc.bias = nn.Parameter(torch.ones(10)*1000)\n",
    "model_linear = F.relu(model2.fc(model_maxpool2.view(model_layer3.size(0), -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(4.2964, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "conv_fused = fuse_conv_and_bn(model2.conv1[0], model2.conv1[1])\n",
    "conv_first = SpikingConv2D(64, \"temp1\", device = 'cpu', padding=(3,3), stride=2, kernel_size=(7,7),robustness_params=robustness_params, kernels=conv_fused.weight.data, biases= conv_fused.bias.data)\n",
    "tmin, tmax = conv_first.set_params(0,1)\n",
    "print(tmin, tmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.1526e-07, grad_fn=<MaxBackward1>)\n",
      "torch.Size([1, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "SNN_input = 1 - random_input\n",
    "model2.conv1.eval() ## Important eval for batch normalization\n",
    "out1 = conv_first(SNN_input.to(\"cpu\"))\n",
    "out1_x = model2.conv1(random_input)\n",
    "print(((conv_first.t_max - out1) - out1_x).abs().max())\n",
    "print(out1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9605e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool = MaxMinPool2D(3, tmax.data,2,1).to(\"cpu\")\n",
    "\n",
    "out2 = pool(out1)\n",
    "out2_x = model2.maxpool(out1_x)\n",
    "\n",
    "print(((tmax - out2) - model_maxpool).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(424.0510, grad_fn=<AddBackward0>) tensor(675.8299, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\3544665386.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\3544665386.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "layer0SNN = LayerSNN(model2.layer0, 64, 64, 3,device = 'cpu')\n",
    "tmin, tmax = layer0SNN.set_params(tmin, tmax)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.9468e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_3 = layer0SNN.forward(out2)\n",
    "\n",
    "print((tmax - out_3 - model_layer0).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(75544.5391, grad_fn=<AddBackward0>) tensor(116697.3906, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\1180262121.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\1180262121.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "layer1SNN = LayerSNN(model2.layer1, 64, 128, 4,device = 'cpu')\n",
    "tmin, tmax = layer1SNN.set_params(tmin, tmax)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0179, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_4 = layer1SNN.forward(out_3)\n",
    "\n",
    "print((tmax - out_4 - model_layer1).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\1180262121.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\1180262121.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0355e+09, grad_fn=<AddBackward0>) tensor(4.6049e+09, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer2SNN = LayerSNN(model2.layer2, 128, 256, 6,device = 'cpu')\n",
    "tmin, tmax = layer2SNN.set_params(tmin, tmax)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2666, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_5 = layer2SNN.forward(out_4)\n",
    "\n",
    "print((tmax - out_5 - model_layer2).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.4699e+14, grad_fn=<AddBackward0>) tensor(1.8168e+15, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\199243283.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\1180262121.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\1180262121.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(max(t_min + self.B_n*max_V, minimal_t_max), dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "layer3SNN = LayerSNN(model2.layer3, 256, 512, 3,device = 'cpu')\n",
    "tmin, tmax = layer3SNN.set_params(tmin, tmax)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8022, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_6 = layer3SNN.forward(out_5)\n",
    "\n",
    "print((tmax - out_6 - model_layer3).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8022, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "pool2 = MaxMinPool2D(7, tmax.data,1,0).to(\"cpu\")\n",
    "\n",
    "out7 = pool2(out_6)\n",
    "\n",
    "print(((tmax - out7) - model_maxpool2).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(out7.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmin, tmax = 0,1\n",
    "# random_input = torch.rand(1,512,1,1)\n",
    "# out7 = 1-random_input\n",
    "\n",
    "# model_linear = F.relu(model2.fc(random_input.view(random_input.size(0), -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spiking_dense = SpikingDense(10,\"test\",robustness_params=robustness_params)\n",
    "# weights = model2.fc.weight.T\n",
    "# spiking_dense.build((512,),weights)\n",
    "# tmin, tmax = spiking_dense.set_params(tmin, tmax)\n",
    "# print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out8 = spiking_dense(out7.view(out7.size(0), -1))\n",
    "# print((tmax - out8 - model_linear).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmin, tmax = 0,1\n",
    "# random_input = torch.rand(1,512,1,1)\n",
    "# out7 = 1-random_input\n",
    "\n",
    "# model_linear = F.relu(model2.fc(random_input.view(random_input.size(0), -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8168e+15, grad_fn=<AddBackward0>) tensor(5.0278e+15, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\1706425233.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min_prev = torch.tensor(t_min_prev, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\1706425233.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_min = torch.tensor(t_min, dtype=torch.float64, requires_grad=False)\n",
      "C:\\Users\\nikos\\AppData\\Local\\Temp\\ipykernel_2140\\1706425233.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.t_max = torch.tensor(t_min + self.B_n*max_V, dtype=torch.float64, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "spiking_dense = SpikingDense(10,\"test\",robustness_params=robustness_params)\n",
    "weights = model2.fc.weight.T\n",
    "biases = model2.fc.bias\n",
    "spiking_dense.build((512,),weights, biases)\n",
    "tmin, tmax = spiking_dense.set_params(tmin, tmax)\n",
    "print(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "out8 = spiking_dense(out7.view(out7.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6101, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((tmax - out8 - model_linear).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_lst = [layer0SNN, layer1SNN, layer2SNN, layer3SNN]\n",
    "ll = []\n",
    "for i in layer_lst:\n",
    "    ll.extend(i.get_main_times())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(4.2964, grad_fn=<AddBackward0>), tensor(9.0893, grad_fn=<AddBackward0>), 'c'), (tensor(9.0893, grad_fn=<AddBackward0>), tensor(40.5616, grad_fn=<AddBackward0>), 'c'), (tensor(40.5616, grad_fn=<AddBackward0>), tensor(103.5064, grad_fn=<AddBackward0>), 'a'), (tensor(103.5064, grad_fn=<AddBackward0>), tensor(129.5853, grad_fn=<AddBackward0>), 'c'), (tensor(129.5853, grad_fn=<AddBackward0>), tensor(172.2720, grad_fn=<AddBackward0>), 'c'), (tensor(172.2720, grad_fn=<AddBackward0>), tensor(298.1615, grad_fn=<AddBackward0>), 'a'), (tensor(298.1615, grad_fn=<AddBackward0>), tensor(317.4261, grad_fn=<AddBackward0>), 'c'), (tensor(317.4261, grad_fn=<AddBackward0>), tensor(424.0510, grad_fn=<AddBackward0>), 'c'), (tensor(424.0510, grad_fn=<AddBackward0>), tensor(675.8299, grad_fn=<AddBackward0>), 'a'), (tensor(675.8299, grad_fn=<AddBackward0>), tensor(954.9916, grad_fn=<AddBackward0>), 'c'), (tensor(954.9916, grad_fn=<AddBackward0>), tensor(3527.0454, grad_fn=<AddBackward0>), 'c'), (tensor(3527.0454, grad_fn=<AddBackward0>), tensor(8671.1523, grad_fn=<AddBackward0>), 'a'), (tensor(8671.1523, grad_fn=<AddBackward0>), tensor(8672.1982, grad_fn=<AddBackward0>), 'c'), (tensor(8672.1982, grad_fn=<AddBackward0>), tensor(13815.2598, grad_fn=<AddBackward0>), 'c'), (tensor(13815.2598, grad_fn=<AddBackward0>), tensor(24103.4746, grad_fn=<AddBackward0>), 'a'), (tensor(24103.4746, grad_fn=<AddBackward0>), tensor(27672.7344, grad_fn=<AddBackward0>), 'c'), (tensor(27672.7344, grad_fn=<AddBackward0>), tensor(34391.6875, grad_fn=<AddBackward0>), 'c'), (tensor(34391.6875, grad_fn=<AddBackward0>), tensor(54968.1133, grad_fn=<AddBackward0>), 'a'), (tensor(54968.1133, grad_fn=<AddBackward0>), tensor(54975.0195, grad_fn=<AddBackward0>), 'c'), (tensor(54975.0195, grad_fn=<AddBackward0>), tensor(75544.5391, grad_fn=<AddBackward0>), 'c'), (tensor(75544.5391, grad_fn=<AddBackward0>), tensor(116697.3906, grad_fn=<AddBackward0>), 'a'), (tensor(116697.3906, grad_fn=<AddBackward0>), tensor(264732.4688, grad_fn=<AddBackward0>), 'c'), (tensor(264732.4688, grad_fn=<AddBackward0>), tensor(825178.8750, grad_fn=<AddBackward0>), 'c'), (tensor(825178.8750, grad_fn=<AddBackward0>), tensor(1946071.6250, grad_fn=<AddBackward0>), 'a'), (tensor(1946071.6250, grad_fn=<AddBackward0>), tensor(5684160.5000, grad_fn=<AddBackward0>), 'c'), (tensor(5684160.5000, grad_fn=<AddBackward0>), tensor(51622196., grad_fn=<AddBackward0>), 'c'), (tensor(51622196., grad_fn=<AddBackward0>), tensor(1.4350e+08, grad_fn=<AddBackward0>), 'a'), (tensor(1.4350e+08, grad_fn=<AddBackward0>), tensor(1.4411e+08, grad_fn=<AddBackward0>), 'c'), (tensor(1.4411e+08, grad_fn=<AddBackward0>), tensor(2.3537e+08, grad_fn=<AddBackward0>), 'c'), (tensor(2.3537e+08, grad_fn=<AddBackward0>), tensor(4.1913e+08, grad_fn=<AddBackward0>), 'a'), (tensor(4.1913e+08, grad_fn=<AddBackward0>), tensor(4.8538e+08, grad_fn=<AddBackward0>), 'c'), (tensor(4.8538e+08, grad_fn=<AddBackward0>), tensor(6.8155e+08, grad_fn=<AddBackward0>), 'c'), (tensor(6.8155e+08, grad_fn=<AddBackward0>), tensor(1.0739e+09, grad_fn=<AddBackward0>), 'a'), (tensor(1.0739e+09, grad_fn=<AddBackward0>), tensor(1.0757e+09, grad_fn=<AddBackward0>), 'c'), (tensor(1.0757e+09, grad_fn=<AddBackward0>), tensor(1.4662e+09, grad_fn=<AddBackward0>), 'c'), (tensor(1.4662e+09, grad_fn=<AddBackward0>), tensor(2.2509e+09, grad_fn=<AddBackward0>), 'a'), (tensor(2.2509e+09, grad_fn=<AddBackward0>), tensor(2.2511e+09, grad_fn=<AddBackward0>), 'c'), (tensor(2.2511e+09, grad_fn=<AddBackward0>), tensor(3.0355e+09, grad_fn=<AddBackward0>), 'c'), (tensor(3.0355e+09, grad_fn=<AddBackward0>), tensor(4.6049e+09, grad_fn=<AddBackward0>), 'a'), (tensor(4.6049e+09, grad_fn=<AddBackward0>), tensor(1.4104e+10, grad_fn=<AddBackward0>), 'c'), (tensor(1.4104e+10, grad_fn=<AddBackward0>), tensor(3.1116e+11, grad_fn=<AddBackward0>), 'c'), (tensor(3.1116e+11, grad_fn=<AddBackward0>), tensor(9.0527e+11, grad_fn=<AddBackward0>), 'a'), (tensor(9.0527e+11, grad_fn=<AddBackward0>), tensor(3.6296e+12, grad_fn=<AddBackward0>), 'c'), (tensor(3.6296e+12, grad_fn=<AddBackward0>), tensor(1.1090e+14, grad_fn=<AddBackward0>), 'c'), (tensor(1.1090e+14, grad_fn=<AddBackward0>), tensor(3.2544e+14, grad_fn=<AddBackward0>), 'a'), (tensor(3.2544e+14, grad_fn=<AddBackward0>), tensor(3.6209e+14, grad_fn=<AddBackward0>), 'c'), (tensor(3.6209e+14, grad_fn=<AddBackward0>), tensor(8.4699e+14, grad_fn=<AddBackward0>), 'c'), (tensor(8.4699e+14, grad_fn=<AddBackward0>), tensor(1.8168e+15, grad_fn=<AddBackward0>), 'a')]\n"
     ]
    }
   ],
   "source": [
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = [i[1].detach().numpy() for i in ll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x247d078d100>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2 = [tt[i]/tt[i-1] for i in range(1,len(tt))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x247d4f643d0>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(tt2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
